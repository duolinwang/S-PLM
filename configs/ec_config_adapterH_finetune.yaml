fix_seed: 0
checkpoints_every: 128
tensorboard_log: True
result_path: ./results_fold_class

resume:
  enable: True
  resume_path: path/to/resume
  restart_optimizer: False

encoder:
  model_name:  facebook/esm2_t33_650M_UR50D # facebook/esm2_t33_650M_UR50D, facebook/esm2_t30_150M_UR50D, facebook/esm2_t12_35M_UR50D, facebook/esm2_t6_8M_UR50D, Rostlab/prot_t5_base_mt_uniref50
  max_len: 512
  tune_embedding: False
  adapter_h:
    enable: True
    num_end_adapter_layers: 16
    module_type: "MLP1"
    freeze_adapter_layers: True
  fine_tune:
    enable: True
    last_layers_trainable: 2
    freeze_adapter_layers: True
  lora:
    enable: False
    r: 8
    lora_alpha: 32
    lora_dropout: 0.05
  num_labels: 538

train_settings:
  data_path:  /mnt/pixstor/dbllab/duolin/downstream/SPLM_Data/EC_data/EC_train.csv
  label_path: /mnt/pixstor/dbllab/duolin/downstream/SPLM_Data/EC_data/nrPDB-EC_annot.tsv
  num_epochs: 200
  shuffle: True
  loss: bce-logit # crossentropy, focal or binary cross entropy with logits (use "bce", BCEWITHLOGITSLoss)
  sample_weight: False
  mixed_precision: fp16 # no, fp16, bf16, fp8
  device: cuda
  batch_size: 64
  num_workers: 0
  grad_accumulation: 1

valid_settings:
  data_path: /mnt/pixstor/dbllab/duolin/downstream/SPLM_Data/EC_data/EC_valid.csv
  label_path: /mnt/pixstor/dbllab/duolin/downstream/SPLM_Data/EC_data/nrPDB-EC_annot.tsv
  do_every: 1
  batch_size: 128
  device: cuda
  num_workers: 0

test_settings:
  data_path: /mnt/pixstor/dbllab/duolin/downstream/SPLM_Data/EC_data/EC_test.csv
  label_path: /mnt/pixstor/dbllab/duolin/downstream/SPLM_Data/EC_data/nrPDB-EC_annot.tsv
  batch_size: 128
  device: cuda
  num_workers: 0

optimizer:
  name: adam
  lr: 0.001
  weight_decouple: True
  weight_decay: 0.0005
  eps: 1e-16
  beta_1: 0.9
  beta_2: 0.999
  use_8bit_adam: False
  grad_clip_norm: 1
  decay:
    warmup: 256
    min_lr: 1e-6
    gamma: 1
    num_restarts: 1
    first_cycle_steps: null # null or an integer number (ignore num_restarts)
